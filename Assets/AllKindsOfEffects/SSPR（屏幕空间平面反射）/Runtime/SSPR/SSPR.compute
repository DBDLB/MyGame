#define NUMTHREAD_X 8
#define NUMTHREAD_Y 8

#define MAX_UINT 0xFFFFFFFF
#pragma kernel PCPathClear
#pragma kernel PCPathRenderHashRT
#pragma kernel PCPathResolveColorRT
#pragma kernel MobilePathSinglePassColorRTDirectResolve
#pragma kernel FillHoles
#pragma kernel GenerateMips
#pragma kernel GaussianBlurHorizontal
#pragma kernel GaussianBlurVertical


#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
//common SamplerState settings
SamplerState PointClampSampler;
SamplerState LinearClampSampler;

float2 _RTSize;
float _ReflectionPlaneHeightWS;
float _FadeOutVerticle;
float _FadeOutHorizontal;
float3 _CameraDirection;
float4x4 MATRIX_I_VP;
float4x4 MATRIX_VP;

//gaussian
float _BlurRadius;
static const float weights[9] = {
	1.0 / 16.0, 4.0 / 16.0, 6.0 / 16.0, 
	4.0 / 16.0, 1.0 / 16.0, 0.0 / 16.0, 
	6.0 / 16.0, 4.0 / 16.0, 1.0 / 16.0
};

//TODO:如果 metal平台有问题，尝试自己传递vp矩阵 
//float4x4 _VPMatrix; 
float _ScreenLRStretchIntensity;
float _ScreenLRStretchThreshold;

//common texture input from SSPRRendererFeature.cs
RWTexture2D<half4> _SSPRCameraTexture;
Texture2D<half4> _CameraOpaqueTexture;
Texture2D<float> _CameraDepthTexture;

RWTexture2D<uint> _HashRT; 

//Mobile(Android) path will use this RT: single 32bit float for PositionWSy
RWTexture2D<float> _SSPRPositionWSyTexture;

//mips
RWTexture2D<half4> _SSRPMipSource;
RWTexture2D<half4> _SSRPMipDest;


float3 ConvertScreenIDToPosWS(uint2 id)
{
	float2 screenUV = float2(id.x / (_RTSize.x), id.y / (_RTSize.y)); //[0,RTSize-1] -> screen [0,1] uv
	float inputPixelRawDepth = _CameraDepthTexture.SampleLevel(PointClampSampler, screenUV, 0);

	float4 posCS = float4(screenUV * 2.0 - 1.0, inputPixelRawDepth, 1.0); //reconstruct posCS using screen [0,1] uv & rawDepth
#if UNITY_UV_STARTS_AT_TOP
	posCS.y = -posCS.y;
#endif
	
	float4 posHWS = mul(MATRIX_I_VP, posCS); //posCS -> posHWS
	float3 posWS = posHWS.xyz / posHWS.w; //posHWS -> posWS

	return posWS;
}
float3 MirrorPosWS(float3 inputPosWS)
{
	float3 reflectedPosWS = inputPosWS;
	reflectedPosWS.y -= _ReflectionPlaneHeightWS;
	reflectedPosWS.y *= -1;//actual reflect action
	reflectedPosWS.y += _ReflectionPlaneHeightWS;

	return reflectedPosWS;
}
float2 ConvertReflectedPosWSToScreenUV(float3 reflectedPosWS)
{
	float4 reflectedPosCS = mul(MATRIX_VP, float4(reflectedPosWS, 1));//posWS -> posCS
	float2 reflectedPosNDCxy = reflectedPosCS.xy / reflectedPosCS.w;//posCS -> posNDC

	float2 reflectedScreenUV = reflectedPosNDCxy * 0.5 + 0.5; //posNDC -> screen [0,1] uv, don't saturate() to allow  out of bound access early exit

	//TODO: 把画面左右弯曲填满画面裁切部分
	float Threshold = _ScreenLRStretchThreshold;
	float Intensity = _ScreenLRStretchIntensity;

	float HeightStretch = (abs(reflectedPosWS.y - _ReflectionPlaneHeightWS));
	float AngleStretch = (-_CameraDirection.y);
	float ScreenStretch = saturate(abs(reflectedScreenUV.x * 2 - 1) - Threshold);

	reflectedScreenUV.x = reflectedScreenUV.x * 2 - 1;
	reflectedScreenUV.x *= 1 + HeightStretch * AngleStretch * ScreenStretch * Intensity;
	reflectedScreenUV.x = saturate(reflectedScreenUV.x * 0.5 + 0.5);
	
#if UNITY_UV_STARTS_AT_TOP
	reflectedScreenUV.y = 1.0 - reflectedScreenUV.y;
#endif

	return reflectedScreenUV;
}
half ConvertOpaqueColorRTScreenUVToFadeAlphaParam(float2 screenUV, float reflectedPosWSy)
{
	//fadeout  using vertical uv.y (only fadeout if reaching _CameraOpaqueTexture's uv border top)
	half fadeoutAlpha = smoothstep(1, 1-_FadeOutVerticle, screenUV.y);
	//fadeout using horizontal uv.x
	//TODO: better fadeout
	fadeoutAlpha *= smoothstep(1, 1 - _FadeOutHorizontal * -(reflectedPosWSy-_ReflectionPlaneHeightWS), abs(screenUV.x * 2 - 1));
	return fadeoutAlpha;
}


[numthreads(NUMTHREAD_X, NUMTHREAD_Y, 1)]
void PCPathClear(uint3 id : SV_DispatchThreadID)
{
	_HashRT[id.xy] = MAX_UINT; //max value as clear, because we want to sort by InterlockedMin()
	_SSPRCameraTexture[uint2(id.xy)] = half4(0, 0, 0, 0);
}

[numthreads(NUMTHREAD_X,NUMTHREAD_Y,1)]
void PCPathRenderHashRT(uint3 id : SV_DispatchThreadID)
{
	float3 posWS = ConvertScreenIDToPosWS(id);

	if(posWS.y <= _ReflectionPlaneHeightWS)
		return;

	//
	float3 reflectedPosWS = MirrorPosWS(posWS);
	
	float2 reflectedScreenUV = ConvertReflectedPosWSToScreenUV(reflectedPosWS);
	//early exit if not valid uv anymore, to avoid out of bound access
	float2 earlyExitTest = abs(reflectedScreenUV - 0.5);
	if (earlyExitTest.x >= 0.5 || earlyExitTest.y >= 0.5)
		return;
	uint2 reflectedScreenID = reflectedScreenUV * _RTSize;//from screen uv[0,1] to [0,RTSize-1]

	float2 screenUV = id.xy / _RTSize;
	half fadeoutAlpha = ConvertOpaqueColorRTScreenUVToFadeAlphaParam(screenUV, reflectedPosWS.y);

	uint fadeoutAlphaInt = fadeoutAlpha * 255;//8 bit
	uint hash = id.y << 20 | id.x << 8 | fadeoutAlphaInt; //pack 3 uint into 1
#if SHADER_API_METAL
	//do nothing because metal will never use this kernel (PC kernel)
#else
	InterlockedMin(_HashRT[reflectedScreenID],hash); //correct sorting method, sort by id.y
#endif
}


[numthreads(NUMTHREAD_X, NUMTHREAD_Y, 1)]
void PCPathResolveColorRT(uint3 id : SV_DispatchThreadID)
{
	uint packedData = _HashRT[id.xy];	
	if (packedData == MAX_UINT) //MAX_UINT == max uint
	{
		//if this location is not having any reflection data (still containing clear value, still 0 reflection write), early exit to prevent wrong RT write
		_SSPRCameraTexture[id.xy] = 0;
		return;
	}	

	//ghost-recon-wildlands method use 16bit y, 16bit x encode
	//but in our implementation, 16bit is overkill because we don't need a RT that is 65536*65536
	//instead we save 8 bits for fadeout alpha info, result in:
	//-first 12 bits for id.y (0~4095)
	//-then  12 bits for id.x (0~4095)
	//-last  8  bits for alpha (0~255)
	uint2 sampleID = uint2((packedData >> 8) & 0xFFF, packedData >> 20); //decode from single 32bit uint, to 3 separated uint (12bit y & 12bit x & 8bit alpha)
	uint alphaAsInt = packedData & 0xFF;
	half alphaAsFloatingPoint = alphaAsInt / 255.0;

	float2 sampleUV = sampleID.xy / _RTSize;
	half3 sampledColor = _CameraOpaqueTexture.SampleLevel(LinearClampSampler, sampleUV, 0);

	half4 finalColor = half4(sampledColor, alphaAsFloatingPoint);
	finalColor.a = saturate(finalColor.a);
	_SSPRCameraTexture[id.xy] = finalColor;
}


[numthreads(NUMTHREAD_X,NUMTHREAD_Y,1)]
void MobilePathSinglePassColorRTDirectResolve(uint3 id : SV_DispatchThreadID)
{
	//black rgb and alpha = 0. alpha 0 means no valid SSPR pixels found, so reflection plane will not use SSRP's result     
    _SSPRCameraTexture[uint2(id.xy)] = half4(0,0,0,0);
	_SSPRPositionWSyTexture[uint2(id.xy)] = 9999999;//a very high posWS.y as clear value

	float3 posWS = ConvertScreenIDToPosWS(id);

	if(posWS.y <= _ReflectionPlaneHeightWS)
		return;

	float3 reflectedPosWS = MirrorPosWS(posWS);

	float2 reflectedScreenUV = ConvertReflectedPosWSToScreenUV(reflectedPosWS);
	//early exit if not valid uv anymore, to avoid out of bound access
	float2 earlyExitTest = abs(reflectedScreenUV - 0.5);
	if (earlyExitTest.x >= 0.5 || earlyExitTest.y >= 0.5) 
		return;
	uint2 reflectedScreenID = reflectedScreenUV * _RTSize;//from screen uv[0,1] to [0,RTSize-1]

	//因为对_SSPRCameraTexture的写入是一个未知的随机顺序(在同一个调度调用中可能有>1个候选对象写入同一个槽!)
	//这里我们只允许“更接近水平反射平面的候选”写入_SSPRCameraTexture & _SSPRPositionWSyTexture。
	//最后，只有“最接近水平反射平面候选”将保留在_SSPRCameraTexture & _SSPRPositionWSyTexture中，这是正确的反射数据
	if(posWS.y < _SSPRPositionWSyTexture[reflectedScreenID])
	{
		float2 screenUV = id.xy / _RTSize;
		half3 inputPixelSceneColor = _CameraOpaqueTexture.SampleLevel(LinearClampSampler, screenUV, 0).rgb;

		half fadeoutAlpha = ConvertOpaqueColorRTScreenUVToFadeAlphaParam(screenUV, reflectedPosWS.y);

		//we write the following data to 2 RTs:
		//-_SSPRCameraTexture.rgba = current best reflection color and alpha(alpha means SSPR usage %)
		//-_SSPRPositionWSyTexture.r = current lowest PosyWS (concept similar to a regular depth buffer ZTest->ZWrite)
		half4 color = half4(inputPixelSceneColor,fadeoutAlpha);
		color.a = saturate(color.a);
		_SSPRCameraTexture[reflectedScreenID] = color;
		_SSPRPositionWSyTexture[reflectedScreenID] = posWS.y;
	}
}


[numthreads(NUMTHREAD_X, NUMTHREAD_Y, 1)]
void FillHoles(uint3 id : SV_DispatchThreadID)
{
	//fill holes inside each 2*2
	id.xy *= 2;

	//cache read
	half4 center = _SSPRCameraTexture[id.xy + uint2(0, 0)];
	half4 right = _SSPRCameraTexture[id.xy + uint2(0, 1)];
	half4 bottom = _SSPRCameraTexture[id.xy + uint2(1, 0)];
	half4 bottomRight = _SSPRCameraTexture[id.xy + uint2(1, 1)];

	//find best inside 2*2
	half4 best = center;
	best = right.a > best.a + 0.5 ? right : best;
	best = bottom.a > best.a + 0.5 ? bottom : best;
	best = bottomRight.a > best.a + 0.5 ? bottomRight : best;

	//write better rgba
	_SSPRCameraTexture[id.xy + uint2(0, 0)] = best.a > center.a + 0.5 ? best : center;
	_SSPRCameraTexture[id.xy + uint2(0, 1)] = best.a > right.a + 0.5 ? best : right;
	_SSPRCameraTexture[id.xy + uint2(1, 0)] = best.a > bottom.a + 0.5 ? best : bottom;
	_SSPRCameraTexture[id.xy + uint2(1, 1)] = best.a > bottomRight.a + 0.5 ? best : bottomRight;
}

float DepthBasedScale(float depth)
{
	const float maxDepth = 10.0; // 最大深度值
	const float minScale = 1.0;   // 最小缩放因子
	const float maxScale = 5.0;   // 最大缩放因子
	return minScale + (maxScale - minScale) * (depth / maxDepth);
}

//模糊
[numthreads(NUMTHREAD_X, NUMTHREAD_Y, 1)]
void GaussianBlurHorizontal(uint3 gid : SV_GroupThreadID, uint3 id : SV_DispatchThreadID)
{
	int2 uv = id.xy;
	
	float2 offset = float2(_BlurRadius, 0);

	float4 blurColorH = 0;
	float w = 0;
	for (int i = -4; i < 4; ++i)
	{
		float4 sample = _SSPRCameraTexture.Load(int3(uv + int2(offset * i), 0));
		blurColorH += sample * weights[abs(i) % 9];
		w += weights[abs(i) % 9];
	}
	blurColorH /= w;
	_SSPRCameraTexture[id.xy] = blurColorH;
}

[numthreads(NUMTHREAD_X, NUMTHREAD_Y, 1)]
void GaussianBlurVertical(uint3 gid : SV_GroupThreadID, uint3 id : SV_DispatchThreadID)
{
	int2 uv = (id.xy);
	
	float2 offset = float2(0, _BlurRadius);
	
	float4 blurColorV = 0.0;
	float w = 0;
	for (int i = -4; i < 4; ++i)
	{
		float4 sample = _SSPRCameraTexture.Load(int3(uv + int2(offset * i), 0));
		blurColorV += sample * weights[abs(i) % 9];
		w += weights[abs(i) % 9];
	}
	blurColorV /= w;
	_SSPRCameraTexture[id.xy] = blurColorV;
}

//生成mips
[numthreads(NUMTHREAD_X, NUMTHREAD_Y, 1)]
void GenerateMips(uint3 id : SV_DispatchThreadID)
{
	if(id.x > (uint)_RTSize.x || id.y > (uint)_RTSize.y)
	{
		return;
	}
	uint2 ori_id = id.xy * 2;
	float4 value = (_SSRPMipSource[ori_id] + _SSRPMipSource[ori_id + uint2(1, 0)] + _SSRPMipSource[ori_id + uint2(0, 1)] + _SSRPMipSource[ori_id + uint2(1, 1)]);
	value /= 4;
	_SSRPMipDest[id.xy] = value;
}
